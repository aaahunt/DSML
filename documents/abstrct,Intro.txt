abstract:
AI is the future and it basically involves the usage of computers to ease out daily human tasks, which makes it crucial for the computer to understand how a human carries out a task. However for the computer to perform accurately it must be trained. ML is the subset of artificial intelligence which focuses on the training of the computer either by using Supervised(labelled data) learning, Unsupervised(unlabelled data), Semi-supervised Learning or Reinforcement Learning.  Our aim here is to train the computer using the labelled data so that it can classify between different hand gestures the human being performs. 
The data was collected using a phyphox app compatible on smartphones which utilises the accelerometer sensors inside the device. The data has gone through a set of preprocessing techniques like application of a low-pass filter, Fourier transformation and PCA to refine the extracted features given to the model for training. We have deployed ML models like SVM, Random Forest Classifier, XGB, KNN and some Recurrent Neural Network Models like LSTM and GRU looking for a optimum fit model for multi class classification between gestures 1. Drawing a circle, 2. Waving, 3. Gesturing come here, 4. Gesturing go away. 
The outcome shows a good  __% accuracy for ___ ML model in comparison with other ML models implemented, and the accuracy of __% LSTM(RNN model) and ___% for GRU(RNN model). 

Introduction: 
Making a computer understand human gesture is a step towards it[3].Gesture recognition pertains to recognizing meaning- ful expressions of motion by a human, involving the hands, arms, face, head, and/or body[20]. With a variety of application across different fields including monitoring activities and vital signs, enhancing gaming experience, and supporting applications in robotics and wearable technology. Our  intent is to use smartphones which is a practically used device to establish  communication possibilities between humans and machines differing from the traditional data collection methods. we further explore the usage of this technology to create accessibility features for individuals with disabilities which could be a potential project within the scope of man machine interaction.
 In recent years, gesture recognition system has become very popular in the field of research, especially facial and hand gesture recognition system[3] gesture classification for hand movement can be classified into static and dynamic depending on the data acquisition method.  In the past a significant amount of research has been carried out which investigates machine algorithms like Support Vector Machine[1][3] , Random Forest[1] , Hidden Markov Model which analyses data to discover patterns. A  few Deep Learning models like CNN[1][6] and some hybrid models like CNN-LSTM[1] mostly focusing on  image processing, which has now made it a common subject in the domain. However a limited amount of research focuses on using signal data collected as a .dataset(.csv file)  using a normally accessible device among humans today. 



