{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "81f78624",
      "metadata": {
        "id": "81f78624"
      },
      "source": [
        "# COMP4030 - Data Science and Machine Learning - Coursework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a601159b",
      "metadata": {},
      "source": [
        "Firstly we ensure that the raw data provided by Phyphox is unzipped and ready for import."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28f4593",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility functions - Ashley Hunt - psyah10\n",
        "import os\n",
        "\n",
        "def get_gestures():\n",
        "      return ['circle', 'come', 'go', 'wave']\n",
        "\n",
        "def get_columns():\n",
        "    return ['time', 'accel_x', 'accel_y', 'accel_z', 'accel_abs']\n",
        "\n",
        "def get_gesture_csvs(gesture_dir):\n",
        "      if not os.path.exists(gesture_dir):\n",
        "            os.makedirs(gesture_dir)\n",
        "      return [file for file in os.listdir(gesture_dir) if file.endswith('.csv')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0316306b",
      "metadata": {},
      "source": [
        "Next we read the raw data from the CSV files and place the data inside a pandas DataFrame. We also use this opportunity to normalise our data using a MinMaxScaler, ensuring that all of our data lies between 0 and 1. This will ensure that no single field plays a more important role than it should."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b85365",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data importing - Ashley Hunt - psyah10\n",
        "import pandas as pd\n",
        "\n",
        "## Simple function to read a csv file and return a dataframe - If scaler is provided, it will scale the data\n",
        "def get_df(path, scaler=None, trim=True):\n",
        "      if not path.endswith('.csv'):\n",
        "            return []\n",
        "      \n",
        "      raw_data = pd.read_csv(path)\n",
        "      raw_data.columns = get_columns()\n",
        "\n",
        "      df = pd.DataFrame(scaler.fit_transform(raw_data) if scaler else raw_data, columns=raw_data.columns)\n",
        "\n",
        "      return trim_recording(df) if trim else df\n",
        "\n",
        "## Function to trim the recording to the first and last significant movement\n",
        "def trim_recording(df, window_size = 20, threshold = 0.3, padding=90):\n",
        "\n",
        "      df['rolling_max'] = df['accel_abs'].rolling(window=window_size, min_periods=1).mean()\n",
        "\n",
        "      start_cut = df[df['rolling_max'] >= threshold].index.min()\n",
        "      if pd.notna(start_cut):\n",
        "            cut_index = max(start_cut - padding, 0)\n",
        "            df = df.loc[cut_index:]\n",
        "      \n",
        "      end_cut = df[df['rolling_max'] >= threshold].index.max()\n",
        "      if pd.notna(end_cut):\n",
        "            end_cut_index = min(end_cut + padding, len(df) - 1) \n",
        "            df = df.loc[:end_cut_index]\n",
        "\n",
        "      df = df.drop('rolling_max', axis=1)\n",
        "      return df\n",
        "\n",
        "## Function to get all the data from the files in the data folder\n",
        "def get_data_from_files(scaler=None, trim=True, test=False):\n",
        "      dfs = []\n",
        "      gestures = get_gestures()\n",
        "      if test:\n",
        "            gestures.append('unknown')\n",
        "      for gesture in gestures:\n",
        "            folder_path = f'data/{gesture}' if not test else f'data/test/{gesture}/'\n",
        "            files_in_folder = get_gesture_csvs(folder_path)\n",
        "            if len(files_in_folder) == 0:\n",
        "                  continue\n",
        "            for file_index, file_name in enumerate(files_in_folder):\n",
        "                  file_path = os.path.join(folder_path, file_name)\n",
        "                  df = get_df(file_path, scaler, trim)\n",
        "                  if len(df) == 0:\n",
        "                        continue\n",
        "\n",
        "                  df['file_number'] = int(file_index)\n",
        "                  df['gesture'] = str(gesture)\n",
        "\n",
        "                  dfs.append(df)\n",
        "                  \n",
        "      df = pd.concat(dfs, ignore_index=True) if len(dfs) > 1 else dfs[0]\n",
        "      df.set_index(['gesture', 'file_number'], inplace=True)\n",
        "      df.sort_index(inplace=True)\n",
        "      return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50bb6a83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data importing - Ashley Hunt - psyah10\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler() ## StandardScaler() or MinMaxScaler()\n",
        "\n",
        "df = get_data_from_files(scaler, trim=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10f1ae2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance ditribution - Ashley Hunt - psyah10\n",
        "\n",
        "def balance_files(df):\n",
        "      for gesture in df.index.get_level_values('gesture').unique():\n",
        "            num_files = len(df.loc[(gesture), :].index.unique())\n",
        "            print(f'{gesture} has {num_files} files (approx. {num_files * 8} gestures)')\n",
        "            \n",
        "      average_num_files = df.reset_index().groupby('gesture')['file_number'].nunique().mean()\n",
        "      print(f'\\nAverage number of files per gesture: {average_num_files}')\n",
        "      \n",
        "      remove = df.index.get_level_values('file_number').unique()[int(average_num_files)]\n",
        "      balanced_df = df[df.index.get_level_values('file_number') < remove]\n",
        "      \n",
        "      print(f'\\nRemoved {len(df) - len(balanced_df)} rows from dataset where file_number >= {remove}')\n",
        "      return balanced_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307a334e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance ditribution - Ashley Hunt - psyah10\n",
        "df = balance_files(df)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a437042",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data importing - Ashley Hunt - psyah10\n",
        "\n",
        "test_df = get_data_from_files(scaler, trim=False, test=True)\n",
        "print(test_df.index.unique(level='gesture'))\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50a702f",
      "metadata": {},
      "source": [
        "Next we visualise our raw data for exploratory analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5372f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising data - Ashley Hunt - psyah10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualise_df(dataframe, files_per_gesture=2):\n",
        "    fig, axs = plt.subplots(4, 2, figsize=(16, 12))\n",
        "\n",
        "    for (gesture, file_number), group in dataframe.loc[(slice(None), range(0,files_per_gesture)), :].groupby(level=['gesture', 'file_number']):\n",
        "\n",
        "            ax = axs[get_gestures().index(gesture), file_number]\n",
        "\n",
        "            for col in get_columns()[1:4]:\n",
        "                ax.plot(range(0, len(group)), group[col], label=col)\n",
        "                ax.set_title(\"{gesture} {file_number}\".format(gesture=gesture, file_number=file_number))\n",
        "                ax.set_xlabel('Index')\n",
        "                ax.set_ylabel('Acceleration')\n",
        "                ax.legend()\n",
        "            \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e023b5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualise_df(df, files_per_gesture=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab77077",
      "metadata": {},
      "source": [
        "Next we apply a low-pass filter to reduce noise from the data and make our model more robust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90334d37",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Low-pass filtering - Ashley Hunt - psyah10\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff_freq, fs, order=5):\n",
        "    nyquist_freq = 0.5 * fs\n",
        "    normal_cutoff = cutoff_freq / nyquist_freq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    filtered_data = filtfilt(b, a, data)\n",
        "    return filtered_data\n",
        "\n",
        "def apply_filter(df, cutoff_freq=2, fs=50, order=5):\n",
        "    new_df = df.copy()\n",
        "    for column in get_columns()[1:]:\n",
        "        new_df[column] = butter_lowpass_filter(new_df[column], cutoff_freq, fs, order)\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f43027",
      "metadata": {},
      "source": [
        "Now we again visualise our data and using interactive widgets we visually evaluate the performance of different parameter settings for apply the filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4206e5cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising data - Ashley Hunt - psyah10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def df_preview(dataframe, files_per_gesture=2):\n",
        "    \n",
        "    plt.clf()\n",
        "    \n",
        "    fig, axs = plt.subplots(4, files_per_gesture, figsize=(15, files_per_gesture * 4))\n",
        "\n",
        "    for (gesture, file_number), group in dataframe.loc[(slice(None), range(0, files_per_gesture)), :].groupby(level=['gesture', 'file_number']):\n",
        "\n",
        "            ax = axs[get_gestures().index(gesture), file_number]\n",
        "\n",
        "            for col in get_columns()[1:4]:\n",
        "                ax.plot(range(0, len(group)), group[col], label=col)\n",
        "                ax.set_title(\"{gesture} {file_number}\".format(gesture=gesture, file_number=file_number))\n",
        "                ax.set_xlabel('Index')\n",
        "                ax.set_ylabel('Acceleration')\n",
        "                ax.legend()\n",
        "            \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b949a62",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter parameter tuning - Ashley Hunt - psyah10\n",
        "%matplotlib inline\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "cutoff_frequency_slider = widgets.IntSlider(value=2, min=1, max=15, step=1, description='cutoff_frequency')\n",
        "sampling_rate_slider = widgets.IntSlider(value=70, min=25, max=150, step=1, description='sampling_rate')\n",
        "filter_order_slider = widgets.IntSlider(value=5, min=1, max=100, step=1, description='filter_order')\n",
        "\n",
        "def update_signal(cutoff_frequency, sampling_rate, filter_order):\n",
        "    filtered_df = apply_filter(df, cutoff_frequency, sampling_rate, filter_order)\n",
        "    df_preview(filtered_df, files_per_gesture=3)\n",
        "\n",
        "interactive_plot = widgets.interactive(update_signal, cutoff_frequency=cutoff_frequency_slider, sampling_rate=sampling_rate_slider, filter_order=filter_order_slider)\n",
        "display(interactive_plot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958f0e5f",
      "metadata": {},
      "source": [
        "Using the best parameters we then apply these settings to our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf02b6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter parameter tuning - Ashley Hunt - psyah10\n",
        "\n",
        "cutoff_frequency = 2  # Cutoff frequency in Hz - Higher = less smoothing\n",
        "sampling_rate = 70  # Sampling rate in Hz - Higher = more smoothing\n",
        "filter_order = 5  # Filter order - Higher = less smoothing\n",
        "\n",
        "df = apply_filter(df, cutoff_frequency, sampling_rate, filter_order)\n",
        "test_df = apply_filter(test_df, cutoff_frequency, sampling_rate, filter_order)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f37f41",
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896e7eab",
      "metadata": {},
      "source": [
        "Now we split the data from distinct files into distinct gestures. We do this by using the natural peaks and troughs in absolute acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021008d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spltting gestures - Ashley Hunt - psyah10\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "def split_file_to_gestures(df, threshold=0.03, padding=10):\n",
        "      gesture_data = []\n",
        "      charts = []\n",
        "      for (gesture, file_number), group in df.groupby(level=['gesture', 'file_number']):\n",
        "            \n",
        "            charts.append(gesture) ## Limit to 2 charts per gesture\n",
        "            \n",
        "            group.reset_index(drop=True, inplace=True)\n",
        "            group.drop(['time'], axis=1, inplace=True)\n",
        "            \n",
        "            peaks, peak_info = find_peaks(group['accel_abs'], height=0.2, distance=20, width=10, prominence=0.1)\n",
        "            \n",
        "            if(len(peaks) < 6 or len(peaks) > 9):\n",
        "                  print(f\"Incorrect peaks in {gesture} {file_number} - {len(peaks)}\")\n",
        "                  plt.plot(group['accel_abs'])\n",
        "                  plt.plot(peaks, group['accel_abs'][peaks], \"x\")\n",
        "                  plt.title(f'{gesture} {file_number}')\n",
        "                  plt.show()\n",
        "            \n",
        "            for peak in peaks:\n",
        "                  \n",
        "                  below_target = group.loc[:peak]\n",
        "                  start_index = below_target[below_target['accel_abs'] < threshold].last_valid_index()\n",
        "                  start_index = max(0, start_index - padding)\n",
        "                  \n",
        "                  above_target = group.loc[peak + 1:]\n",
        "                  end_index = above_target[above_target['accel_abs'] < threshold].first_valid_index()\n",
        "                  end_index = min(len(group), end_index + padding)\n",
        "                  \n",
        "                  data = group.loc[start_index:end_index].copy()\n",
        "                  \n",
        "                  data['gesture_number'] = len(gesture_data)\n",
        "                  data['gesture'] = gesture\n",
        "                  gesture_data.append(data)\n",
        "      \n",
        "      gesture_df = pd.concat(gesture_data, ignore_index=True)\n",
        "      gesture_df.set_index(['gesture', 'gesture_number'], inplace=True)\n",
        "      return gesture_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d6932f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spltting gestures - Ashley Hunt - psyah10\n",
        "gesture_df = split_file_to_gestures(df, threshold=0.03, padding=10)\n",
        "gesture_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc234614",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spltting gestures - Ashley Hunt - psyah10\n",
        "\n",
        "test_gesture_df = split_file_to_gestures(test_df, threshold=0.03, padding=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7721673",
      "metadata": {},
      "source": [
        "Now we visualise these gestures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "220ed2b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising data - Ashley Hunt - psyah10\n",
        "\n",
        "def visualise_gestures(dataframe, n):\n",
        "      charts = []\n",
        "      plt.figure(figsize=(n * 4, 10))\n",
        "      for (gesture, gesture_number), group in dataframe.groupby(level=['gesture', 'gesture_number']):\n",
        "            \n",
        "            charts.append(gesture) ## Limit charts per gesture\n",
        "            if(charts.count(gesture) > n):\n",
        "                  continue\n",
        "            \n",
        "            gesture_i = get_gestures().index(gesture)\n",
        "            plt.subplot(4, n, (n * gesture_i ) + charts.count(gesture) )\n",
        "            \n",
        "            group.reset_index(drop=True, inplace=True)\n",
        "            for col in get_columns()[1:4]:\n",
        "                  plt.plot(range(len(group)), group[col], label=col)\n",
        "                  plt.title(\"{gesture} {gesture_number}\".format(gesture=gesture, gesture_number=gesture_number))\n",
        "                  plt.ylim(0, 1)\n",
        "      plt.subplots_adjust(hspace=0.4)\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d72df9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising data - Ashley Hunt - psyah10\n",
        "\n",
        "visualise_gestures(gesture_df, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf087f1f",
      "metadata": {},
      "source": [
        "If, due to slicing errors, there are duplicate gestures we will remove them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390a1b3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing duplicate slices - Ashley Hunt - psyah10\n",
        "\n",
        "def remove_duplicate_gestures(dataframe):\n",
        "      data = dataframe.copy()\n",
        "      \n",
        "      data_columns = get_columns()[1:]\n",
        "      group_columns = ['gesture', 'gesture_number']\n",
        "\n",
        "      grouped = data.groupby(group_columns)\n",
        "\n",
        "      group_representations = {}\n",
        "      duplicates_found = False\n",
        "      for name, group in grouped:\n",
        "            group_tuple = tuple(group.sort_values(by=data_columns)[data_columns].itertuples(index=False, name=None))\n",
        "            \n",
        "            if group_tuple in group_representations:\n",
        "                  duplicates_found = True\n",
        "                  data = data.drop(name)\n",
        "                  print(\"Removing identical gestures\", name, \"and\", group_representations[group_tuple])\n",
        "            group_representations[group_tuple] = name\n",
        "            \n",
        "      if not duplicates_found:\n",
        "            print(\"No duplicate gestures found\")\n",
        "      return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49037df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing duplicate slices - Ashley Hunt - psyah10\n",
        "\n",
        "gesture_df = remove_duplicate_gestures(gesture_df)\n",
        "test_gesture_df = remove_duplicate_gestures(test_gesture_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7feb85c",
      "metadata": {},
      "source": [
        "Next we apply a Fourier transformation on the data and filter out the frequencies in the data that are not adding useful information. This is achieved using trial and error through visualisation of the wave before and after transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1a4793",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fourier Transformation - Ashley Hunt - psyah10\n",
        "import numpy as np\n",
        "\n",
        "def fft_filter(data, sample_rate, cutoff_freq_low, cutoff_freq_high):\n",
        "    fft_data = np.fft.fft(data)\n",
        "    freqs = np.fft.fftfreq(len(data), 1/sample_rate)\n",
        "\n",
        "    mask = (freqs > cutoff_freq_low) & (freqs < cutoff_freq_high)\n",
        "    fft_data[~mask] = 0\n",
        "\n",
        "    filtered_signal = np.fft.ifft(fft_data).real\n",
        "    return filtered_signal\n",
        "\n",
        "def apply_fft_filter(data, sample_rate, cutoff_freq_low, cutoff_freq_high):\n",
        "    new_df = data.copy()\n",
        "    for column in get_columns()[1:4]:\n",
        "        new_df[column] = fft_filter(new_df[column], sample_rate, cutoff_freq_low, cutoff_freq_high)\n",
        "    return new_df\n",
        "\n",
        "def visually_compare_fft(original_df, filtered_df, visualise_n=3):\n",
        "\n",
        "    for name, group in original_df.groupby(level='gesture'):\n",
        "        \n",
        "        first_n_gestures = group.index.get_level_values('gesture_number').unique()[:visualise_n]\n",
        "        data = group[group.index.get_level_values('gesture_number').isin(first_n_gestures)]\n",
        "        \n",
        "        for n, g_data in data.groupby(level='gesture_number'):\n",
        "\n",
        "            plt.figure(figsize=(10, 2))\n",
        "\n",
        "            plt.subplot(1, 2, 1)\n",
        "            for col in get_columns()[1:4]:\n",
        "                plt.plot(range(len(g_data)), g_data[col], label=f'Original {col}', alpha=0.5)\n",
        "            plt.title(f\"{name}, {n}\")\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            filtered_data = filtered_df.loc[(name, n)]\n",
        "            for col in get_columns()[1:4]:\n",
        "                plt.plot(range(len(filtered_data)), filtered_data[col], label=f'Filtered {col}', linestyle='--')\n",
        "            plt.title(f'Filtered {name}')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f015a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fourier Transformation - Ashley Hunt - psyah10\n",
        " \n",
        "sample_rate = 1000  # Sampling rate (Hz)\n",
        "cutoff_low = 1  # Low cutoff frequency (Hz)\n",
        "cutoff_high = 20  # High cutoff frequency (Hz) \n",
        "\n",
        "fft_filtered_gestures_df = apply_fft_filter(gesture_df, sample_rate, cutoff_low, cutoff_high)\n",
        "fft_test_filtered_gestures_df = apply_fft_filter(test_gesture_df, sample_rate, cutoff_low, cutoff_high)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6051e28c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualise the FFT filter alongside the original data\n",
        "visually_compare_fft(gesture_df, fft_filtered_gestures_df, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b603b9f8",
      "metadata": {},
      "source": [
        "Next we can begin to extract our features for the models. These functions split the data into a fixed number of segments with some overlap and then take some key statistical values from these slices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f4ebbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extraction - Ashley Hunt - psyah10\n",
        "\n",
        "def extract_segments(df, num_segments, overlap_fraction):\n",
        "    total_rows = len(df)\n",
        "    segment_size = total_rows // num_segments\n",
        "    overlap_size = int(segment_size * overlap_fraction)\n",
        "    \n",
        "    segments = []\n",
        "    \n",
        "    for i in range(num_segments):\n",
        "        start_idx = i * segment_size\n",
        "        if i > 0:\n",
        "            start_idx -= overlap_size\n",
        "        \n",
        "        if i == num_segments - 1:\n",
        "            end_idx = total_rows\n",
        "        else:\n",
        "            end_idx = start_idx + segment_size + overlap_size\n",
        "\n",
        "        segments.append(df.iloc[start_idx:end_idx])\n",
        "    \n",
        "    return segments\n",
        "\n",
        "def extract_features_from_df(df, feature_functions, num_segments = 4, overlap_fraction = 0.1):\n",
        "      results = []\n",
        "      \n",
        "      for (gesture, gesture_number), group in df.groupby(level=['gesture', 'gesture_number']):\n",
        "            \n",
        "            group.reset_index(drop=True, inplace=True)\n",
        "\n",
        "            result_dict = {}\n",
        "            segments = extract_segments(group, num_segments, overlap_fraction)\n",
        "            result_dict['gesture'] = gesture\n",
        "            for n, segment in enumerate(segments):\n",
        "                  for col in get_columns()[1:4]:\n",
        "                        for f in feature_functions:\n",
        "                              result_dict[f'{col}_{f}_{n+1}'] = segment[col].agg(f)\n",
        "\n",
        "            results.append(result_dict)\n",
        "\n",
        "      return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c973dc8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extraction - Ashley Hunt - psyah10\n",
        "\n",
        "# Function options 'mean', 'min', 'max', 'median', 'std', 'skew', 'kurtosis', 'quantile'\n",
        "feature_functions = ['mean', 'min', 'max', 'std', 'kurtosis', 'skew'] \n",
        "num_segments = 8\n",
        "overlap_fraction = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e10633fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extraction - Ashley Hunt - psyah10\n",
        "\n",
        "extracted_features = extract_features_from_df(fft_filtered_gestures_df, feature_functions, num_segments, overlap_fraction)\n",
        "extracted_test_features = extract_features_from_df(fft_test_filtered_gestures_df, feature_functions, num_segments, overlap_fraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2cba61",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting Feature extraction for feature selection - Ashley Hunt - psyah10\n",
        "\n",
        "def show_trends(dataframe):\n",
        "      for f in feature_functions:\n",
        "            plt.figure(figsize=(15, 3))\n",
        "            for col in get_columns()[1:4]:\n",
        "                  plt.subplot(1, 3, get_columns().index(col))\n",
        "                  plt.title(col)\n",
        "                  for g in get_gestures():\n",
        "                        points = []\n",
        "                        for s in range(1, num_segments + 1):\n",
        "                              points.append( dataframe.loc[dataframe[\"gesture\"] == g][f'{col}_{f}_{s}'].mean())\n",
        "                        plt.plot(range(1, num_segments + 1), points, marker='o', linestyle='-', label=g)\n",
        "                        plt.xlabel('Segment')\n",
        "                        plt.ylabel(f)\n",
        "                        plt.legend()\n",
        "                        plt.xticks(range(1, num_segments + 1))\n",
        "            plt.suptitle(f\"{f} by segment\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdae5682",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting Feature extraction for feature selection - Ashley Hunt - psyah10\n",
        "\n",
        "show_trends(extracted_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5e27d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting Feature extraction for feature selection - Ashley Hunt - psyah10\n",
        "\n",
        "def show_trend(dataframe, function, charts_per_gesture=4):\n",
        "      \n",
        "      for g in get_gestures():\n",
        "            if len(dataframe.loc[dataframe[\"gesture\"] == g]) == 0:\n",
        "                  continue\n",
        "            plt.figure(figsize=(charts_per_gesture * 4, 3))\n",
        "            plt.title(f\"{charts_per_gesture} {g}'s {function}\")\n",
        "            for graphs in range(0, charts_per_gesture):\n",
        "                  plt.subplot(1, charts_per_gesture, graphs + 1)\n",
        "                  \n",
        "                  data = dataframe.loc[dataframe[\"gesture\"] == g].iloc[graphs]\n",
        "                  for col in get_columns()[1:4]:\n",
        "                        points = []\n",
        "                        for s in range(1, num_segments + 1):\n",
        "                              points.append(data[f'{col}_{function}_{s}'])\n",
        "                        plt.plot(range(1, num_segments + 1), points, marker='o', linestyle='-', label=col)\n",
        "                  plt.legend()\n",
        "                  plt.xticks(range(1, num_segments + 1))\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed25df4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting Feature extraction for feature selection - Ashley Hunt - psyah10\n",
        "\n",
        "# for f in feature_functions:\n",
        "#       show_trend(extracted_features, f, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b6bd7ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance data - Ashley Hunt - psyah10\n",
        "\n",
        "# Find out the minimum number of gestures in a category\n",
        "min_gestures = extracted_features['gesture'].value_counts().min()\n",
        "\n",
        "# Drop the extra gestures\n",
        "extracted_features = extracted_features.groupby('gesture').head(min_gestures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581286f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "def extract_principle_components(dataframe, components=2):\n",
        "      \n",
        "      data = dataframe.reset_index()\n",
        "      gestures = data['gesture']\n",
        "      data = data.loc[:, (data.columns != 'gesture') & (data.columns != 'index')]\n",
        "\n",
        "      pca = PCA(n_components=components)\n",
        "      principal_components = pca.fit_transform(data)\n",
        "      cols = [f'principal component {i}' for i in range(1, components + 1)]\n",
        "      principle_df = pd.DataFrame(data = principal_components, columns = cols)\n",
        "\n",
        "      # Visualising the PCA results\n",
        "      plt.figure(figsize=(components * 4, components * 4))\n",
        "      for i in range(1, components + 1):\n",
        "            for j in range(1, components + 1):\n",
        "                  if i == j:\n",
        "                        continue\n",
        "                  plt.subplot(components, components, (i - 1) * components + j)\n",
        "                  sns.scatterplot(x=f\"principal component {i}\", y=f\"principal component {j}\", data=principle_df, hue=gestures, palette=\"deep\")\n",
        "                  plt.title(f\"Principle Component Extraction {i} vs {j}\")\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      return principle_df, gestures\n",
        "\n",
        "principle_features, principle_gestures = extract_principle_components(extracted_features, components=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6379291",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label encoding - Ashley Hunt - psyah10\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "def encode_labels(labels):\n",
        "    return label_encoder.fit_transform(labels)\n",
        "\n",
        "def decode_labels(encoded_labels):\n",
        "    return label_encoder.inverse_transform(encoded_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8185a116",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data splitting - Ashley Hunt - psyah10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = extracted_features.loc[:, extracted_features.columns != 'gesture']\n",
        "Y = encode_labels(extracted_features['gesture'])\n",
        "\n",
        "# X = principalDf\n",
        "# Y = encode_labels(gestures)\n",
        "\n",
        "UNSEEN_FEATURES = extracted_test_features.loc[:, extracted_test_features.columns != 'gesture']\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7a9d62",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Training - Ashley Hunt - psyah10\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rfc_model.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd48fb7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Evaluation - Ashley Hunt - psyah10\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "rfc_prediction = rfc_model.predict(test_features)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(test_labels, rfc_prediction)}\")\n",
        "print(classification_report(test_labels, rfc_prediction))\n",
        "\n",
        "unseen_feature_prediction = rfc_model.predict(UNSEEN_FEATURES)\n",
        "print(\"Prediction on unseen data:\", decode_labels(unseen_feature_prediction))\n",
        "\n",
        "actual_unseen_data = ['circle', 'circle', 'come', 'come', 'go', 'go', 'wave', 'wave']\n",
        "print(\"Actual unseen data:\", actual_unseen_data)\n",
        "unseen_results = [a == b for a, b in zip(actual_unseen_data, decode_labels(unseen_feature_prediction))]\n",
        "print(\"Accuracy:\", unseen_results.count(True) / len(unseen_results))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b1b7beb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Support Vector Machines - Ashley Hunt - psyah10\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "svm_model.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f00b84c",
      "metadata": {},
      "outputs": [],
      "source": [
        "svm_y_pred = svm_model.predict(test_features)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(test_labels, svm_y_pred)}\")\n",
        "print(classification_report(test_labels, svm_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a240df63",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ashley Hunt - psyah10\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap\n",
        "               }\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "\n",
        "DO_MODEL_TUNING = False\n",
        "\n",
        "if(DO_MODEL_TUNING):\n",
        "      rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1, error_score='raise')\n",
        "      rf_random.fit(train_features, train_labels)\n",
        "      \n",
        "      rf_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4926be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def evaluate(model, test_features, test_labels):\n",
        "#     predictions = model.predict(test_features)\n",
        "#     errors = abs(predictions - test_labels)\n",
        "#     mape = 100 * np.mean(errors / test_labels)\n",
        "#     accuracy = 100 - mape\n",
        "#     print('Model Performance')\n",
        "#     print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "#     print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "#     return accuracy\n",
        "\n",
        "# base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
        "# base_model.fit(features, encoded_labels)\n",
        "# base_accuracy = evaluate(base_model, test_features, test_labels)\n",
        "\n",
        "# best_random = rf_random.best_estimator_\n",
        "# random_accuracy = evaluate(best_random, test_features, test_labels)\n",
        "\n",
        "# print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec45e629",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Amit Kumar\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "\n",
        "# for train_index, test_index in sss.split(features, encoded_labels):\n",
        "#     train_features, test_features = features[train_index], features[test_index]\n",
        "#     train_labels, test_labels = encoded_labels[train_index], encoded_labels[test_index]\n",
        "#     print(f\"  Test:  index={test_index}\")\n",
        "#     print(f\"  Train: index={train_index}\")\n",
        "    \n",
        "# rfc = RandomForestClassifier(random_state=42)\n",
        " \n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 150],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4]\n",
        "# }\n",
        " \n",
        "# grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, scoring='balanced_accuracy')\n",
        "# grid_search.fit(train_features, train_labels)\n",
        "\n",
        "# best_params = grid_search.best_params_\n",
        "# best_estimator = grid_search.best_estimator_\n",
        " \n",
        "# y_pred = best_estimator.predict(test_features)\n",
        "# balanced_accuracy = balanced_accuracy_score(test_labels, y_pred)\n",
        "# print(\"Best Parameters:\", best_params)\n",
        "# print(\"Balanced Accuracy:\", balanced_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d6582f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Amit Kumar\n",
        "# from xgboost import XGBClassifier\n",
        " \n",
        "# sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        " \n",
        "# for train_index, test_index in sss.split(X, y):\n",
        "#     train_features, test_features = X[train_index], X[test_index]\n",
        "#     train_labels, test_labels = y[train_index], y[test_index]\n",
        "    \n",
        "# xgb_classifier = XGBClassifier(random_state=42)\n",
        " \n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 150],\n",
        "#     'max_depth': [3, 5, 7],\n",
        "#     'learning_rate': [0.1, 0.01, 0.001],\n",
        "#     'subsample': [0.8, 0.9, 1.0],\n",
        "#     'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "# }\n",
        " \n",
        "# grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='balanced_accuracy', cv=5)\n",
        "# grid_search.fit(train_features, train_labels)\n",
        " \n",
        "# best_params = grid_search.best_params_\n",
        "# best_estimator = grid_search.best_estimator_\n",
        " \n",
        "# y_pred = best_estimator.predict(test_features)\n",
        " \n",
        "# balanced_accuracy = balanced_accuracy_score(test_labels, y_pred)\n",
        "# print(\"Best Parameters:\", best_params)\n",
        "# print(\"Balanced Accuracy:\", balanced_accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
