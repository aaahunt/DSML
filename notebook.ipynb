{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "81f78624",
      "metadata": {
        "id": "81f78624"
      },
      "source": [
        "# COMP4030 - Data Science and Machine Learning - Coursework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a601159b",
      "metadata": {},
      "source": [
        "## Data collection and pre-processing\n",
        "At this stage you can toggle which gestures you want to include in the training and testing by adding or removing elements from this functions return array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8956acb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_gestures():\n",
        "      return ['circle', 'go', 'come', 'wave'] # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28f4593",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility functions - Ashley Hunt - psyah10\n",
        "import os\n",
        "\n",
        "def num_gestures():\n",
        "      return len(get_gestures())\n",
        "\n",
        "def get_columns():\n",
        "    return ['time', 'accel_x', 'accel_y', 'accel_z', 'accel_abs']\n",
        "\n",
        "def get_gesture_csvs(gesture_dir):\n",
        "      if not os.path.exists(gesture_dir):\n",
        "            os.makedirs(gesture_dir)\n",
        "      return [file for file in os.listdir(gesture_dir) if file.endswith('.csv')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0316306b",
      "metadata": {},
      "source": [
        "### Data Importing\n",
        "Next we read the raw data from the CSV files and place the data inside a pandas DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b85365",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data importing functions - Ashley Hunt - psyah10\n",
        "import pandas as pd\n",
        "\n",
        "## Simple function to read a csv file and return a dataframe\n",
        "def get_df(path, trim=True):\n",
        "      if not path.endswith('.csv'):\n",
        "            return []\n",
        "      \n",
        "      raw_data = pd.read_csv(path)\n",
        "      raw_data.columns = get_columns()\n",
        "\n",
        "      df = pd.DataFrame(raw_data, columns=raw_data.columns)\n",
        "\n",
        "      return trim_recording(df) if trim else df\n",
        "\n",
        "## Function to trim the recording to the first and last significant movement\n",
        "def trim_recording(df, window_size = 20, threshold = 0.3, padding=90):\n",
        "\n",
        "      df['rolling_max'] = df['accel_abs'].rolling(window=window_size, min_periods=1).mean()\n",
        "\n",
        "      start_cut = df[df['rolling_max'] >= threshold].index.min()\n",
        "      if pd.notna(start_cut):\n",
        "            cut_index = max(start_cut - padding, 0)\n",
        "            df = df.loc[cut_index:]\n",
        "      \n",
        "      end_cut = df[df['rolling_max'] >= threshold].index.max()\n",
        "      if pd.notna(end_cut):\n",
        "            end_cut_index = min(end_cut + padding, len(df) - 1) \n",
        "            df = df.loc[:end_cut_index]\n",
        "\n",
        "      df = df.drop('rolling_max', axis=1)\n",
        "      return df\n",
        "\n",
        "## Function to get all the data from the files in the data folder\n",
        "def get_data_from_files(trim=True, test=False):\n",
        "      sub_folder = 'test' if test else 'train'\n",
        "      \n",
        "      dfs = []\n",
        "      gestures = get_gestures() + (['unknown'] if test else [])\n",
        "      \n",
        "      for gesture in gestures:\n",
        "            folder_path = f'data/{sub_folder}/{gesture}'\n",
        "            files_in_folder = get_gesture_csvs(folder_path)\n",
        "            \n",
        "            if len(files_in_folder) == 0:\n",
        "                  continue\n",
        "            \n",
        "            for file_index, file_name in enumerate(files_in_folder):\n",
        "                  file_path = os.path.join(folder_path, file_name)\n",
        "                  df = get_df(file_path, trim)\n",
        "                  if len(df) == 0:\n",
        "                        continue\n",
        "\n",
        "                  df['file_number'] = int(file_index)\n",
        "                  df['gesture'] = str(gesture)\n",
        "\n",
        "                  dfs.append(df)\n",
        "                  \n",
        "      df = pd.concat(dfs, ignore_index=True) if len(dfs) > 1 else dfs[0]\n",
        "      df.set_index(['gesture', 'file_number'], inplace=True)\n",
        "      df.sort_index(inplace=True)\n",
        "      return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50bb6a83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data importing - Ashley Hunt - psyah10\n",
        "\n",
        "df = get_data_from_files(trim=False, test=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3663af6d",
      "metadata": {},
      "source": [
        "### Data Balancing\n",
        "In order to ensure a balanced data set we find the minimum number of file contributions for each gesture and only take that number of files for every gesture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10f1ae2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance distribution functions - Ashley Hunt - psyah10\n",
        "\n",
        "def balance_files(df):\n",
        "      for gesture in df.index.get_level_values('gesture').unique():\n",
        "            num_files = len(df.loc[(gesture), :].index.unique())\n",
        "            print(f'{gesture} has {num_files} files (approx. {num_files * 8} gestures)')\n",
        "            \n",
        "      min_num_files = df.reset_index().groupby('gesture')['file_number'].nunique().min()\n",
        "      print(f'\\nAverage number of files per gesture: {min_num_files}')\n",
        "      \n",
        "      unique_file_numbers = df.index.get_level_values('file_number').unique()\n",
        "      if len(unique_file_numbers) > min_num_files:\n",
        "            remove = unique_file_numbers[min_num_files]\n",
        "            balanced_df = df[df.index.get_level_values('file_number') < remove]\n",
        "            print(f'\\nRemoved from dataset where file_number >= {remove}')\n",
        "      else :\n",
        "            balanced_df = df\n",
        "      \n",
        "      return balanced_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307a334e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance distribution - Ashley Hunt - psyah10\n",
        "df = balance_files(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae0291df",
      "metadata": {},
      "source": [
        "### Unseen Test data\n",
        "Alongside our labelled data sets we also process additional, unlabelled data that will not be seen my the model as it trains and will be used for validation only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a437042",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test data importing - Ashley Hunt - psyah10\n",
        "\n",
        "test_df = get_data_from_files(trim=False, test=True)\n",
        "test_df = balance_files(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50a702f",
      "metadata": {},
      "source": [
        "### Data visualisation and exploration\n",
        "Next we visualise our raw data for exploratory analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5372f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising data functions - Ashley Hunt - psyah10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualise_df(dataframe, columns, files_per_gesture=2):\n",
        "    \n",
        "    second_level_name = dataframe.index.get_level_values(1).name\n",
        "    num_gestures = dataframe.index.get_level_values('gesture').unique().size\n",
        "    files = min(len(dataframe.index.get_level_values(second_level_name).unique()), files_per_gesture)\n",
        "    \n",
        "    fig, axs = plt.subplots(num_gestures, files, figsize=(14, num_gestures * 2))\n",
        "\n",
        "    for (gesture, file_number), group in dataframe.loc[(slice(None), range(0,files)), :].groupby(level=['gesture', second_level_name]):\n",
        "\n",
        "            try:\n",
        "                indx = get_gestures().index(gesture)\n",
        "            except ValueError:\n",
        "                indx = num_gestures - 1\n",
        "                \n",
        "            ax =  axs[indx, file_number] if files > 1 else axs[indx]\n",
        "\n",
        "            for col in columns:\n",
        "                ax.plot(range(0, len(group)), group[col], label=col)\n",
        "                ax.set_title(\"{gesture} {file_number}\".format(gesture=gesture, file_number=file_number))\n",
        "                ax.set_xlabel('Index')\n",
        "                ax.set_ylabel('Acceleration')\n",
        "                ax.legend()\n",
        "            \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "def compare_dfs(df1, df2, visualise_n=3, new_label=''):\n",
        "    \n",
        "    num_rows = len(df1.index.get_level_values('gesture').unique()) * visualise_n\n",
        "    \n",
        "    fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(14, 2 * num_rows))\n",
        "\n",
        "    for gn, (name, group) in enumerate(df1.groupby(level='gesture')):\n",
        "        \n",
        "        second_level_name = df1.index.get_level_values(1).name\n",
        "        \n",
        "        first_n_gestures = group.index.get_level_values(second_level_name).unique()[:visualise_n]\n",
        "        data = group[group.index.get_level_values(second_level_name).isin(first_n_gestures)]\n",
        "        \n",
        "        for idx, (n, g_data) in enumerate(data.groupby(level=second_level_name)):\n",
        "                \n",
        "                row = idx + gn * visualise_n\n",
        "                ax = axes[row, 0]\n",
        "                for col in get_columns()[1:4]:\n",
        "                    ax.plot(range(len(g_data)), g_data[col], label=col)\n",
        "                ax.set_title(f\"{name} {n}\")\n",
        "                ax.legend(loc='lower left')\n",
        "\n",
        "                ax = axes[row, 1]\n",
        "                filtered_data = df2.loc[(name, n)]\n",
        "                for col in get_columns()[1:4]:\n",
        "                    ax.plot(range(len(filtered_data)), filtered_data[col], label=col)\n",
        "                ax.set_title(f'{name} {n} - After {new_label}')\n",
        "                ax.legend(loc='lower left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e023b5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualise_df(df, ['accel_x', 'accel_y', 'accel_z'], files_per_gesture=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ecc91e",
      "metadata": {},
      "source": [
        "### EWMA Filtering\n",
        "To eradicate spikes in the data, we apply exponentially weighted moving average (EWMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01528ddd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply exponential moving average - Ashley Hunt - psyah10\n",
        "ewm_filtered_df = df.ewm(span=10, adjust=False).mean()\n",
        "compare_dfs(df, ewm_filtered_df, visualise_n=2, new_label=\"EWMA filter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a44c49",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = ewm_filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02e50a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "ewm_filtered_test_df = test_df.ewm(span=10, adjust=False).mean()\n",
        "compare_dfs(test_df, ewm_filtered_test_df, visualise_n=1, new_label=\"EWMA filter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119fa580",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = ewm_filtered_test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab77077",
      "metadata": {},
      "source": [
        "### Low-Pass Filtering\n",
        "Next we apply a low-pass filter to reduce noise from the data and make our model more robust. First we visualise our data and using interactive widgets we visually evaluate the performance of different parameter settings for apply the filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90334d37",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Low-pass filtering functions - Ashley Hunt - psyah10\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff_freq, fs, order=5):\n",
        "    nyquist_freq = 0.5 * fs\n",
        "    normal_cutoff = cutoff_freq / nyquist_freq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    filtered_data = filtfilt(b, a, data)\n",
        "    return filtered_data\n",
        "\n",
        "def apply_filter(df, cutoff_freq=2, fs=50, order=5):\n",
        "    new_df = df.copy()\n",
        "    for column in get_columns()[1:]:\n",
        "        new_df[column] = butter_lowpass_filter(new_df[column], cutoff_freq, fs, order)\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b949a62",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive filter parameter tuning - Ashley Hunt - psyah10\n",
        "%matplotlib inline\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "cutoff_frequency_slider = widgets.IntSlider(value=3, min=1, max=15, step=1, description='cutoff_frequency')\n",
        "sampling_rate_slider = widgets.IntSlider(value=150, min=10, max=150, step=1, description='sampling_rate')\n",
        "filter_order_slider = widgets.IntSlider(value=3, min=1, max=15, step=1, description='filter_order')\n",
        "\n",
        "def update_signal(cutoff_frequency, sampling_rate, filter_order):\n",
        "    filtered_df = apply_filter(df, cutoff_frequency, sampling_rate, filter_order)\n",
        "    compare_dfs(df, filtered_df, visualise_n=1)\n",
        "\n",
        "interactive_plot = widgets.interactive(update_signal, cutoff_frequency=cutoff_frequency_slider, sampling_rate=sampling_rate_slider, filter_order=filter_order_slider)\n",
        "display(interactive_plot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958f0e5f",
      "metadata": {},
      "source": [
        "Using the best parameters we then apply these settings to our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf02b6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter parameter tuning - Ashley Hunt - psyah10\n",
        "\n",
        "cutoff_frequency = 3  # Cutoff frequency in Hz - Higher = less smoothing\n",
        "sampling_rate = 150  # Sampling rate in Hz - Higher = more smoothing\n",
        "filter_order = 5  # Filter order - Higher = less smoothing\n",
        "\n",
        "df = apply_filter(df, cutoff_frequency, sampling_rate, filter_order)\n",
        "test_df = apply_filter(test_df, cutoff_frequency, sampling_rate, filter_order)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896e7eab",
      "metadata": {},
      "source": [
        "### Gesture segmentation\n",
        "Now we split the data from distinct files into distinct gestures. We do this by using the natural peaks and troughs in absolute acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021008d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spltting gestures functions - Ashley Hunt - psyah10\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "def split_file_to_gestures(df, threshold, padding, height, distance, width, prominence):\n",
        "      gesture_data = []\n",
        "      charts = []\n",
        "      for (gesture, file_number), group in df.groupby(level=['gesture', 'file_number']):\n",
        "            \n",
        "            charts.append(gesture) ## Limit to 2 charts per gesture\n",
        "            \n",
        "            group.reset_index(drop=True, inplace=True)\n",
        "            group.drop(['time'], axis=1, inplace=True)\n",
        "            \n",
        "            peaks, peak_info = find_peaks(group['accel_abs'], height=height, distance=distance, width=width, prominence=prominence)\n",
        "            \n",
        "            if(len(peaks) < 6 or len(peaks) > 10):\n",
        "                  print(f\"Incorrect peaks in {gesture} #{file_number} ({len(peaks)} peaks)\")\n",
        "                  plt.plot(group['accel_abs'])\n",
        "                  plt.plot(peaks, group['accel_abs'][peaks], \"x\")\n",
        "                  plt.title(f'{gesture} {file_number}')\n",
        "                  plt.show()\n",
        "            \n",
        "            for peak in peaks:\n",
        "                  \n",
        "                  below_target = group.loc[:peak]\n",
        "                  start_index = below_target[below_target['accel_abs'] < threshold].last_valid_index() #or 0\n",
        "                  start_index = max(0, start_index - padding)\n",
        "                  \n",
        "                  above_target = group.loc[peak + 1:]\n",
        "                  end_index = above_target[above_target['accel_abs'] < threshold].first_valid_index() #or len(group) - 1\n",
        "                  end_index = min(len(group), end_index + padding)\n",
        "                  \n",
        "                  data = group.loc[start_index:end_index].copy()\n",
        "                  \n",
        "                  data['gesture_number'] = len(gesture_data)\n",
        "                  data['gesture'] = gesture\n",
        "                  gesture_data.append(data)\n",
        "      \n",
        "      gesture_df = pd.concat(gesture_data, ignore_index=True)\n",
        "      gesture_df.set_index(['gesture', 'gesture_number'], inplace=True)\n",
        "      return gesture_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d6932f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spltting gestures - Ashley Hunt - psyah10\n",
        "\n",
        "# Parameters for splitting gestures, we adjust these to see which ones resulted in the best splitting\n",
        "\n",
        "threshold=4\n",
        "padding=15\n",
        "height=3\n",
        "distance=20\n",
        "width=30\n",
        "prominence=0\n",
        "\n",
        "gesture_df = split_file_to_gestures(df, threshold, padding, height, distance, width, prominence)\n",
        "test_gesture_df = split_file_to_gestures(test_df, threshold, padding, height, distance, width, prominence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7721673",
      "metadata": {},
      "source": [
        "Now we visualise these gestures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "220ed2b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising gesture functions - Ashley Hunt - psyah10\n",
        "\n",
        "def visualise_gestures(dataframe, n):\n",
        "      \n",
        "      num_gestures = dataframe.index.get_level_values('gesture').unique().size\n",
        "      \n",
        "      charts = []\n",
        "      plt.figure(figsize=(n * num_gestures, 10))\n",
        "      for (gesture, gesture_number), group in dataframe.groupby(level=['gesture', 'gesture_number']):\n",
        "            \n",
        "            charts.append(gesture) ## Limit charts per gesture\n",
        "            if(charts.count(gesture) > n):\n",
        "                  continue\n",
        "            \n",
        "            gesture_i = len(pd.Series(charts).unique()) - 1\n",
        "            plt.subplot(num_gestures, n, (n * gesture_i ) + charts.count(gesture) )\n",
        "            \n",
        "            group.reset_index(drop=True, inplace=True)\n",
        "            for col in get_columns()[1:4]:\n",
        "                  plt.plot(range(len(group)), group[col], label=col)\n",
        "                  plt.title(\"{gesture} {gesture_number}\".format(gesture=gesture, gesture_number=gesture_number))\n",
        "                  plt.legend()\n",
        "                  # plt.ylim(0, 1)\n",
        "      plt.subplots_adjust(hspace=0.4)\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d72df9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising data - Ashley Hunt - psyah10\n",
        "\n",
        "visualise_gestures(gesture_df, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e28b8dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising test data - Ashley Hunt - psyah10\n",
        "\n",
        "visualise_gestures(test_gesture_df, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf087f1f",
      "metadata": {},
      "source": [
        "If, due to slicing errors, there are duplicate gestures we will remove them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390a1b3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing duplicate functions - Ashley Hunt - psyah10\n",
        "\n",
        "def remove_duplicate_gestures(dataframe):\n",
        "      data = dataframe.copy()\n",
        "      \n",
        "      data_columns = get_columns()[1:]\n",
        "      group_columns = ['gesture', 'gesture_number']\n",
        "\n",
        "      grouped = data.groupby(group_columns)\n",
        "\n",
        "      group_representations = {}\n",
        "      duplicates_found = False\n",
        "      for name, group in grouped:\n",
        "            group_tuple = tuple(group.sort_values(by=data_columns)[data_columns].itertuples(index=False, name=None))\n",
        "            \n",
        "            if group_tuple in group_representations:\n",
        "                  duplicates_found = True\n",
        "                  data = data.drop(name)\n",
        "                  print(\"Removing identical gestures\", name, \"and\", group_representations[group_tuple])\n",
        "            group_representations[group_tuple] = name\n",
        "            \n",
        "      if not duplicates_found:\n",
        "            print(\"No duplicate gestures found\")\n",
        "      return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49037df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing duplicate slices - Ashley Hunt - psyah10\n",
        "\n",
        "gesture_df = remove_duplicate_gestures(gesture_df)\n",
        "test_gesture_df = remove_duplicate_gestures(test_gesture_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7feb85c",
      "metadata": {},
      "source": [
        "### Fourier Transformation & Filtering\n",
        "Next we apply a Fourier transformation on the data and filter out the frequencies in the data that are not adding useful information. This is achieved using trial and error through visualisation of the wave before and after transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b76b7772",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_fft(data, sample_rate):\n",
        "      fft_data = np.fft.fft(data)\n",
        "      fft_magnitude = np.abs(fft_data)\n",
        "      fft_frequency = np.fft.fftfreq(len(data), d=1/sample_rate)\n",
        "      return fft_frequency, fft_magnitude\n",
        "\n",
        "def filter_low_magnitude(frequencies, magnitudes):\n",
        "      filtered_frequencies = []\n",
        "      filtered_magnitudes = []\n",
        "      \n",
        "      for freq, mag in zip(frequencies, magnitudes):\n",
        "            if mag >= 500 and freq >= 0:\n",
        "                  filtered_frequencies.append(freq)\n",
        "                  filtered_magnitudes.append(mag)\n",
        "\n",
        "      filtered_frequencies = np.array(filtered_frequencies)\n",
        "      filtered_magnitudes = np.array(filtered_magnitudes)\n",
        "      \n",
        "      return filtered_frequencies, filtered_magnitudes\n",
        "\n",
        "def plot_frequency_spectrums(data, sample_rate):\n",
        "      plt.figure(figsize=(12, 6))\n",
        "      for col in get_columns()[1:4]:\n",
        "            freq, mag = compute_fft(data[col], sample_rate)\n",
        "            filtered_freq, filtered_mag = filter_low_magnitude(freq, mag)\n",
        "            plt.plot(filtered_freq, filtered_mag, label=col)\n",
        "            plt.title('Frequency Spectrum')\n",
        "            plt.xlabel('Frequency (Hz)')\n",
        "            plt.xlim(-0.1)\n",
        "            plt.ylabel('Magnitude')\n",
        "            plt.legend()\n",
        "      plt.show()\n",
        "      \n",
        "plot_frequency_spectrums(gesture_df, 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4982b9a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fourier Transformation functions - Ashley Hunt - psyah10\n",
        "import numpy as np\n",
        "\n",
        "def fft_filter(data, sample_rate, cutoff_freq_low, cutoff_freq_high):\n",
        "    fft_data = np.fft.fft(data)\n",
        "    freqs = np.fft.fftfreq(len(data), 1/sample_rate)\n",
        "\n",
        "    mask = (freqs > cutoff_freq_low) & (freqs < cutoff_freq_high)\n",
        "    fft_data[~mask] = 0\n",
        "\n",
        "    filtered_signal = np.fft.ifft(fft_data).real\n",
        "    return filtered_signal\n",
        "\n",
        "def apply_fft_filter(data, sample_rate, cutoff_freq_low, cutoff_freq_high):\n",
        "    new_df = data.copy()\n",
        "    for column in get_columns()[1:4]:\n",
        "        new_df[column] = fft_filter(new_df[column], sample_rate, cutoff_freq_low, cutoff_freq_high)\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f015a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fourier Transformation - Ashley Hunt - psyah10\n",
        " \n",
        "sample_rate = 60  # Sampling rate (Hz)\n",
        "cutoff_low = 0  # Low cutoff frequency (Hz)\n",
        "cutoff_high = 1.5  # High cutoff frequency (Hz)\n",
        "\n",
        "fft_filtered_gestures_df = apply_fft_filter(gesture_df, sample_rate, cutoff_low, cutoff_high)\n",
        "fft_test_filtered_gestures_df = apply_fft_filter(test_gesture_df, sample_rate, cutoff_low, cutoff_high)\n",
        "\n",
        "compare_dfs(gesture_df, fft_filtered_gestures_df, visualise_n=1, new_label=\"FFT Filtering\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373e4a17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualise the FFT filter alongside the original data (test data)\n",
        "compare_dfs(test_gesture_df, fft_test_filtered_gestures_df, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43662e8f",
      "metadata": {},
      "source": [
        "### Data Normalisation\n",
        "\n",
        "At this point we also normalise our data using a MinMaxScaler, ensuring that all of our data lies between 0 and 1. This will ensure that no single field plays a more important role than it should."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d389f0b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler() ## StandardScaler() or MinMaxScaler()\n",
        "\n",
        "gesture_df[gesture_df.columns] = scaler.fit_transform(gesture_df[gesture_df.columns])\n",
        "test_gesture_df[test_gesture_df.columns] = scaler.fit_transform(test_gesture_df[test_gesture_df.columns])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b603b9f8",
      "metadata": {},
      "source": [
        "## Feature Extraction\n",
        "Next we can begin to extract our features for the models. These functions split the data into a fixed number of segments with some overlap and then take some key statistical values from these slices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f4ebbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extraction functions - Ashley Hunt - psyah10\n",
        "\n",
        "def extract_segments(df, num_segments, overlap_fraction):\n",
        "    total_rows = len(df)\n",
        "    segment_size = total_rows // num_segments\n",
        "    overlap_size = int(segment_size * overlap_fraction)\n",
        "    \n",
        "    segments = []\n",
        "    \n",
        "    for i in range(num_segments):\n",
        "        start_idx = i * segment_size\n",
        "        if i > 0:\n",
        "            start_idx -= overlap_size\n",
        "        \n",
        "        if i == num_segments - 1:\n",
        "            end_idx = total_rows\n",
        "        else:\n",
        "            end_idx = start_idx + segment_size + overlap_size\n",
        "\n",
        "        segments.append(df.iloc[start_idx:end_idx])\n",
        "    \n",
        "    return segments\n",
        "\n",
        "def extract_features_from_df(df, feature_functions, num_segments = 4, overlap_fraction = 0.1):\n",
        "      results = []\n",
        "      \n",
        "      for (gesture, gesture_number), group in df.groupby(level=['gesture', 'gesture_number']):\n",
        "            \n",
        "            group.reset_index(drop=True, inplace=True)\n",
        "\n",
        "            result_dict = {}\n",
        "            segments = extract_segments(group, num_segments, overlap_fraction)\n",
        "            result_dict['gesture'] = gesture\n",
        "            for n, segment in enumerate(segments):\n",
        "                  for col in get_columns()[1:4]:\n",
        "                        for f in feature_functions:\n",
        "                              result_dict[f'{col}_{f}_{n+1}'] = segment[col].agg(f)\n",
        "\n",
        "            results.append(result_dict)\n",
        "\n",
        "      return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c973dc8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extraction - Ashley Hunt - psyah10\n",
        "\n",
        "# Function options 'mean', 'min', 'max', 'median', 'std', 'skew', 'kurtosis', 'quantile'\n",
        "feature_functions = ['mean', 'min', 'max', 'median', 'std', 'skew', 'kurtosis', 'quantile'] \n",
        "num_segments = 8\n",
        "overlap_fraction = 0.5\n",
        "\n",
        "# If using FFT filtered data\n",
        "extracted_features = extract_features_from_df(fft_filtered_gestures_df, feature_functions, num_segments, overlap_fraction)\n",
        "extracted_test_features = extract_features_from_df(fft_test_filtered_gestures_df, feature_functions, num_segments, overlap_fraction)\n",
        "\n",
        "# If NOT using FFT filtered data\n",
        "# extracted_features = extract_features_from_df(gesture_df, feature_functions, num_segments, overlap_fraction)\n",
        "# extracted_test_features = extract_features_from_df(test_gesture_df, feature_functions, num_segments, overlap_fraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd22a8f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_features.dropna(how='any', inplace=True)\n",
        "extracted_test_features.dropna(how='any', inplace=True)\n",
        "\n",
        "extracted_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5562bc6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import cycle\n",
        "# For each 'uknown' gesture in extracted_test_features replace with gestures from get_gestures() in a cycle\n",
        "\n",
        "repeats_in_tests = 2\n",
        "repeated = [element for element in get_gestures() for _ in range(repeats_in_tests)]\n",
        "unknown_indices = extracted_test_features.index[extracted_test_features['gesture'] == 'unknown'].tolist()\n",
        "\n",
        "gesture_cycle = cycle(repeated)\n",
        "replacements = [next(gesture_cycle) for _ in range(len(unknown_indices))]\n",
        "\n",
        "for index, replacement in zip(unknown_indices, replacements):\n",
        "    extracted_test_features.at[index, 'gesture'] = replacement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69fc2dbb",
      "metadata": {},
      "source": [
        "## Feature Selection\n",
        "Now we visulaise the extracted features to help us determine which features are most useful in classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2cba61",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting Feature extraction functions - Ashley Hunt - psyah10\n",
        "\n",
        "def show_trends(dataframe):\n",
        "      for f in feature_functions:\n",
        "            plt.figure(figsize=(15, 3))\n",
        "            for col in get_columns()[1:4]:\n",
        "                  plt.subplot(1, 3, get_columns().index(col))\n",
        "                  plt.title(col)\n",
        "                  for g in get_gestures():\n",
        "                        points = []\n",
        "                        for s in range(1, num_segments + 1):\n",
        "                              points.append( dataframe.loc[dataframe[\"gesture\"] == g][f'{col}_{f}_{s}'].mean())\n",
        "                        plt.plot(range(1, num_segments + 1), points, marker='o', linestyle='-', label=g)\n",
        "                        plt.xlabel('Segment')\n",
        "                        plt.ylabel(f)\n",
        "                        plt.legend()\n",
        "                        plt.xticks(range(1, num_segments + 1))\n",
        "            plt.suptitle(f\"{f} by segment\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb13a33c",
      "metadata": {},
      "source": [
        "### Feature visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdae5682",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting Feature extraction for feature selection - Ashley Hunt - psyah10\n",
        "\n",
        "# show_trends(extracted_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5e27d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting individual feature extraction for selection - Ashley Hunt - psyah10\n",
        "\n",
        "def show_trend(dataframe, function, charts_per_gesture=4):\n",
        "      \n",
        "      for g in get_gestures():\n",
        "            if len(dataframe.loc[dataframe[\"gesture\"] == g]) == 0:\n",
        "                  continue\n",
        "            plt.figure(figsize=(charts_per_gesture * 4, 3))\n",
        "            plt.title(f\"{charts_per_gesture} {g}'s {function}\")\n",
        "            for graphs in range(0, charts_per_gesture):\n",
        "                  plt.subplot(1, charts_per_gesture, graphs + 1)\n",
        "                  \n",
        "                  data = dataframe.loc[dataframe[\"gesture\"] == g].iloc[graphs]\n",
        "                  for col in get_columns()[1:4]:\n",
        "                        points = []\n",
        "                        for s in range(1, num_segments + 1):\n",
        "                              points.append(data[f'{col}_{function}_{s}'])\n",
        "                        plt.plot(range(1, num_segments + 1), points, marker='o', linestyle='-', label=col)\n",
        "                  plt.legend()\n",
        "                  plt.xticks(range(1, num_segments + 1))\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed25df4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisting Feature extraction for feature selection - Ashley Hunt - psyah10\n",
        "\n",
        "# for f in feature_functions:\n",
        "#       show_trend(extracted_features, f, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7d13630",
      "metadata": {},
      "source": [
        "### Rebalance data\n",
        "Once again we reblance our data, this time on the total number of observations for each gesture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b6bd7ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance data functions - Ashley Hunt - psyah10\n",
        "\n",
        "def rebalance_data(dataframe):\n",
        "      # Find out the minimum number of gestures in a category\n",
        "      min_gestures = dataframe['gesture'].value_counts().min()\n",
        "\n",
        "      # Take only the top x gestures\n",
        "      return dataframe.groupby('gesture').head(min_gestures)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c3a76f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-balance data - Ashley Hunt - psyah10\n",
        "\n",
        "extracted_features = rebalance_data(extracted_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581286f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Principle Component Analysis & Extraction functions - Ashley Hunt - psyah10\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "def extract_principle_components(dataframe, components=2):\n",
        "      \n",
        "      data = dataframe.reset_index()\n",
        "      gestures = data['gesture']\n",
        "      data = data.loc[:, (data.columns != 'gesture') & (data.columns != 'index')]\n",
        "\n",
        "      pca = PCA(n_components=components)\n",
        "      principal_components = pca.fit_transform(data)\n",
        "      cols = [f'principal component {i}' for i in range(1, components + 1)]\n",
        "      principle_df = pd.DataFrame(data = principal_components, columns = cols)\n",
        "      principle_df['gesture'] = gestures\n",
        "\n",
        "      return principle_df\n",
        "\n",
        "def visualise_principle_components(dataframe):\n",
        "      cols = len(dataframe.columns) - 1\n",
        "      plt.figure(figsize=(cols * 3, cols * 3))\n",
        "      sns.pairplot(dataframe, hue=\"gesture\", palette=\"deep\")\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef8713c",
      "metadata": {},
      "source": [
        "### Principle Component Analysis\n",
        "\n",
        "We then utilise PCA to do automatic feature selection. This is easy to extract and does not rely on subjective human input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ecdb21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Principle Component Analysis & Extraction - Ashley Hunt - psyah10\n",
        "\n",
        "NUM_PCA_COMPONENTS = 2\n",
        "\n",
        "principle_features = extract_principle_components(extracted_features, components=NUM_PCA_COMPONENTS)\n",
        "test_principle_features = extract_principle_components(extracted_test_features, components=NUM_PCA_COMPONENTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27b5de1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising Principle Component Analysis - Ashley Hunt - psyah10\n",
        "visualise_principle_components(principle_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368a0f0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualising Principle Component Analysis - Ashley Hunt - psyah10\n",
        "visualise_principle_components(test_principle_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f924fe6a",
      "metadata": {},
      "source": [
        "## Model Training\n",
        "First we prepare out label encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6379291",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label encoding functions - Ashley Hunt - psyah10\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "def encode_labels(labels):\n",
        "    return label_encoder.fit_transform(labels)\n",
        "\n",
        "def decode_labels(encoded_labels):\n",
        "    return label_encoder.inverse_transform(encoded_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c382e35",
      "metadata": {},
      "source": [
        "Then we extract the data that we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8185a116",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data splitting - Ashley Hunt - psyah10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "PRINCIPLE = True\n",
        "\n",
        "if PRINCIPLE:\n",
        "      X = principle_features.loc[:, principle_features.columns != 'gesture']\n",
        "      Y = encode_labels(principle_features['gesture'])\n",
        "      UNSEEN_FEATURES = test_principle_features.loc[:, test_principle_features.columns != 'gesture']\n",
        "      UNSEEN_LABELS = encode_labels(test_principle_features['gesture'])\n",
        "else:\n",
        "      X = extracted_features.loc[:, extracted_features.columns != 'gesture']\n",
        "      Y = encode_labels(extracted_features['gesture'])\n",
        "      UNSEEN_FEATURES = extracted_test_features.loc[:, extracted_test_features.columns != 'gesture']\n",
        "      UNSEEN_LABELS = encode_labels(extracted_test_features['gesture'])\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfd71120",
      "metadata": {},
      "source": [
        "### K-means Clustering\n",
        "As the first, most basic, option for classification we consider a K-means clustering algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37a4a06",
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-means clustering functions - Ashley Hunt - psyah10\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "k = num_gestures()\n",
        "\n",
        "kmeans_model = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
        "kmeans_model.fit(train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c6530a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-means clustering visualisation - Ashley Hunt - psyah10\n",
        "\n",
        "def visualise_kmeans(dataframe, model):\n",
        "      kmeans_data = dataframe.copy()\n",
        "      kmeans_data['Cluster'] = model.fit_predict(dataframe)\n",
        "      kmeans_data['Gesture'] = decode_labels(train_labels)\n",
        "\n",
        "      sns.scatterplot( data = kmeans_data, x='principal component 1', y='principal component 2', hue='Gesture', palette='viridis', style='Cluster', s=100)\n",
        "      plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1], c='red', s=100, alpha=0.5, label='Centroids')\n",
        "      plt.title('K-means Clustering on PCA-Reduced Data')\n",
        "      plt.xlabel('principal component 1')\n",
        "      plt.ylabel('principal component 2')\n",
        "      plt.legend()\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72254f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualise_kmeans(train_features, kmeans_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba06f1f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing/Validation display functions - Ashley Hunt - psyah10\n",
        "\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "def show_confusion_matrix(actual, predictions):\n",
        "      \n",
        "      fig, ax = plt.subplots(figsize=(8, 6))\n",
        "      \n",
        "      labels = decode_labels(unique_labels(actual))\n",
        "      cm_df = pd.DataFrame(confusion_matrix(actual, predictions), index=labels, columns=labels)\n",
        "\n",
        "      # plt.figure(figsize=(7, 5))\n",
        "      sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap='Blues', cbar=True, square=True, linewidth=.5, ax=ax)\n",
        "      \n",
        "      # Loop over the data dimensions and outline the diagonal cells\n",
        "      for i in range(cm_df.shape[0]):\n",
        "            for j in range(cm_df.shape[1]):\n",
        "                  if i == j: \n",
        "                        rect = plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='green', lw=1)\n",
        "                        ax.add_patch(rect)\n",
        "      \n",
        "      plt.title('Confusion Matrix')\n",
        "      plt.ylabel('Actual', labelpad=20)\n",
        "      plt.xlabel('Predicted', labelpad=20)\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      \n",
        "def show_classification_report(actual, predictions):\n",
        "      print(f\"Accuracy: {accuracy_score(actual, predictions)}\")\n",
        "      print(classification_report(actual, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e12cfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-means Evaluation - Ashley Hunt - psyah10\n",
        "kmeans_predictions = kmeans_model.predict(test_features)\n",
        "print('Silhouette Score:', silhouette_score(test_features, kmeans_predictions))\n",
        "show_classification_report(test_labels, kmeans_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b5771a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-means Validation - Ashley Hunt - psyah10\n",
        "\n",
        "kmeans_prediction = kmeans_model.predict(UNSEEN_FEATURES)\n",
        "\n",
        "show_classification_report(UNSEEN_LABELS, kmeans_prediction)\n",
        "show_confusion_matrix(UNSEEN_LABELS, kmeans_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e503b4",
      "metadata": {},
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7a9d62",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Training - Ashley Hunt - psyah10\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rfc_model.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd48fb7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Evaluation - Ashley Hunt - psyah10\n",
        "\n",
        "rfc_prediction = rfc_model.predict(test_features)\n",
        "\n",
        "show_classification_report(test_labels, rfc_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc91676",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Hypertuning  Ashley Hunt - psyah10\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['auto', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               }\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1, error_score='raise')\n",
        "rf_random.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb349e18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Hypertuning  Ashley Hunt - psyah10\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "rf_best_params = rf_random.best_params_\n",
        "rf_best_estimator = rf_random.best_estimator_\n",
        "\n",
        "rf_predictions = rf_best_estimator.predict(test_features)\n",
        "balanced_accuracy = balanced_accuracy_score(test_labels, rf_predictions)\n",
        "\n",
        "print(\"Best Parameters:\", rf_best_params)\n",
        "print(\"Balanced Accuracy:\", balanced_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f70bc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Validation - Ashley Hunt - psyah10\n",
        "rfc_unseen_feature_prediction = rf_best_estimator.predict(UNSEEN_FEATURES)\n",
        "\n",
        "show_classification_report(UNSEEN_LABELS, rfc_unseen_feature_prediction)\n",
        "show_confusion_matrix(UNSEEN_LABELS, rfc_unseen_feature_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e0bbb7",
      "metadata": {},
      "source": [
        "### Support Vector Machines "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b1b7beb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Support Vector Machines Training - Ashley Hunt - psyah10\n",
        "from sklearn import svm\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear')\n",
        "svm_model.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f00b84c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Support Vector Machines Evaluation - Ashley Hunt - psyah10\n",
        "svm_prediction = svm_model.predict(test_features)\n",
        "\n",
        "show_classification_report(test_labels, svm_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaeedee7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Support Vector Machines Validation - Ashley Hunt - psyah10\n",
        "\n",
        "svm_unseen_feature_prediction = svm_model.predict(UNSEEN_FEATURES)\n",
        "\n",
        "show_classification_report(UNSEEN_LABELS, svm_unseen_feature_prediction)\n",
        "show_confusion_matrix(UNSEEN_LABELS, svm_unseen_feature_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e1f9438",
      "metadata": {},
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce65d305",
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGB - Amit Kumar\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [300],\n",
        "    'max_depth': [20],\n",
        "    'learning_rate': [0.1],\n",
        "    'subsample': [0.8],\n",
        "    'colsample_bytree': [1]\n",
        "}\n",
        "\n",
        "#param_grid = {\n",
        "    #'n_estimators': [50, 100, 150],\n",
        "    #'max_depth': [3, 5, 7],\n",
        "    #'learning_rate': [0.1, 0.01, 0.001],\n",
        "    #'subsample': [0.8, 0.9, 1.0],\n",
        "    #'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "#}\n",
        "\n",
        "knn_grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy')\n",
        "knn_grid_search.fit(train_features, train_labels)\n",
        "\n",
        "best_params = knn_grid_search.best_params_\n",
        "best_estimator = knn_grid_search.best_estimator_\n",
        "\n",
        "rf_predictions = best_estimator.predict(test_features)\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy_score(test_labels, rf_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c73961e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGB Validation - Ashley Hunt - psyah10\n",
        "\n",
        "xgb_unseen_feature_prediction = best_estimator.predict(UNSEEN_FEATURES)\n",
        "\n",
        "show_classification_report(UNSEEN_LABELS, xgb_unseen_feature_prediction)\n",
        "show_confusion_matrix(UNSEEN_LABELS, xgb_unseen_feature_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c39ae1",
      "metadata": {},
      "source": [
        "### Long Short-Term Memory layer (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86fbd35e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LSTM - Amit Kumar\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "data = df.copy().reset_index()\n",
        "\n",
        "# Encode the gesture labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['gesture_encoded'] = label_encoder.fit_transform(data['gesture'])\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "data[['accel_x', 'accel_y', 'accel_z', 'accel_abs']] = scaler.fit_transform(data[['accel_x', 'accel_y', 'accel_z', 'accel_abs']])\n",
        "\n",
        "# Define the time steps\n",
        "time_steps = 10\n",
        "\n",
        "# Prepare the data for LSTM\n",
        "def prepare_data_for_lstm(data, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        X.append(data.iloc[i:(i + time_steps)].values)\n",
        "        y.append(data.iloc[i + time_steps]['gesture_encoded'])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = prepare_data_for_lstm(data[['accel_x', 'accel_y', 'accel_z', 'accel_abs', 'gesture_encoded']], time_steps)\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax')) # Change activation to softmax for multi-class classification\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Change loss function for multi-class classification\n",
        "\n",
        "# Train the model with validation data\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "_, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5fb7138",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LSTM - Amit Kumar\n",
        "test_data = test_df.copy().reset_index()\n",
        "\n",
        "# Preprocess the new data\n",
        "test_data['gesture_encoded'] = label_encoder.transform(test_data['gesture'])  # Use the same label encoder as before\n",
        "test_data[['accel_x', 'accel_y', 'accel_z', 'accel_abs']] = scaler.transform(test_data[['accel_x', 'accel_y', 'accel_z', 'accel_abs']])\n",
        " \n",
        "# Prepare the new data for evaluation\n",
        "X_new, y_new = prepare_data_for_lstm(test_data[['accel_x', 'accel_y', 'accel_z', 'accel_abs', 'gesture_encoded']], time_steps)\n",
        " \n",
        "y_pred_prob = model.predict(X_new)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        " \n",
        "# Create a mask for the misclassified samples where the predicted label matches the input label\n",
        "misclassified_mask = y_pred == y_new\n",
        " \n",
        "# Invert the mask to get the indices of misclassified samples\n",
        "misclassified_indices = np.logical_not(misclassified_mask)\n",
        " \n",
        "# Decode the predicted labels back into gesture names\n",
        "predicted_gestures = label_encoder.inverse_transform(y_pred)\n",
        " \n",
        "# Display the gestures with their corresponding predicted labels and accuracy\n",
        "print(\"Gesture\\t\\tPredicted Label\")\n",
        "print(\"=============================\")\n",
        "for i in range(len(predicted_gestures)):\n",
        "    # If the sample is misclassified, mark it as such in the output\n",
        "    if misclassified_indices[i]:\n",
        "        print(f\"{test_data.iloc[i]['gesture']}\\t\\t{predicted_gestures[i]} (Misclassified)\")\n",
        "    else:\n",
        "        print(f\"{test_data.iloc[i]['gesture']}\\t\\t{predicted_gestures[i]}\")\n",
        " \n",
        "# Calculate and display the overall accuracy\n",
        "correct_predictions = np.sum(misclassified_mask)\n",
        "total_predictions = len(y_new)\n",
        "overall_accuracy = correct_predictions / total_predictions\n",
        "print(\"\\nOverall Accuracy on Test Data:\", overall_accuracy)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f61d1ac",
      "metadata": {},
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c96898",
      "metadata": {},
      "outputs": [],
      "source": [
        "# KNN - Shreeya Kumbhoje - psxsk19\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "knn = KNeighborsClassifier()\n",
        " \n",
        "\n",
        "pipeline = Pipeline([('knn', knn)])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'knn__n_neighbors': [3, 5, 7, 9, 11], \n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__metric': ['euclidean', 'manhattan']\n",
        "}\n",
        " \n",
        "\n",
        "knn_grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
        "knn_grid_search.fit(train_features, train_labels)\n",
        " \n",
        "\n",
        "print(\"Best parameters:\", knn_grid_search.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(knn_grid_search.best_score_))\n",
        " \n",
        "\n",
        "knn_best_model = knn_grid_search.best_estimator_\n",
        "knn_predictions = knn_best_model.predict(test_features)\n",
        "\n",
        "show_classification_report(test_labels, knn_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6103269d",
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_unseen_test_pred = knn_best_model.predict(UNSEEN_FEATURES)\n",
        "\n",
        "show_classification_report(UNSEEN_LABELS, knn_unseen_test_pred)\n",
        "show_confusion_matrix(UNSEEN_LABELS, knn_unseen_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9355a6cf",
      "metadata": {},
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a79e927",
      "metadata": {},
      "outputs": [],
      "source": [
        "# GRU Model - Shreeya - psxsk19\n",
        "\n",
        "gesture_df.reset_index(inplace=True)\n",
        "gesture_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090be9c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Shreeya Kumbhoje - psxsk19\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "np.random.seed(38)\n",
        "random.seed(38)\n",
        "tf.random.set_seed(38)\n",
        "\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32929fa2",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Shreeya Kumbhoje - psxsk19\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(38)\n",
        "random.seed(38)\n",
        "tf.random.set_seed(38)\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "gesture_df.reset_index()\n",
        "\n",
        "\n",
        "N = gesture_df['gesture'].nunique()\n",
        "\n",
        "\n",
        "gesture_df['label'] = gesture_df['gesture'].astype('category').cat.codes\n",
        "\n",
        "\n",
        "grouped = gesture_df.groupby(['gesture', 'gesture_number'])\n",
        "sequences = [group[1][['accel_x', 'accel_y', 'accel_z', 'accel_abs']].values for group in grouped]\n",
        "labels = [group[1]['label'].iloc[0] for group in grouped]\n",
        "\n",
        "\n",
        "sequences_train, sequences_test, labels_train, labels_test = train_test_split(\n",
        "    sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "X_train = pad_sequences(sequences_train, padding='post', dtype='float32')\n",
        "X_test = pad_sequences(sequences_test, padding='post', dtype='float32', maxlen=X_train.shape[1])\n",
        "\n",
        "\n",
        "y_train = to_categorical(labels_train, num_classes=N)\n",
        "y_test = to_categorical(labels_test, num_classes=N)\n",
        "\n",
        "\n",
        "timesteps = X_train.shape[2]  \n",
        "model = Sequential([\n",
        "    GRU(64, input_shape=(timesteps, 4), return_sequences=True),\n",
        "    GRU(32),\n",
        "    Dense(N, activation='softmax')  \n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=25, batch_size=10)\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
