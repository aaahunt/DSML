{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ashley Hunt - psyah10\n",
    "import os\n",
    "\n",
    "def get_gestures():\n",
    "      return ['circle', 'come', 'go', 'wave']\n",
    "\n",
    "def get_columns():\n",
    "    return ['time', 'accel_x', 'accel_y', 'accel_z', 'accel_abs']\n",
    "\n",
    "def get_gesture_csvs(gesture):\n",
    "      gesture_dir = os.path.join(os.getcwd(), \"data\", gesture)\n",
    "      return [file for file in os.listdir(gesture_dir) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############Use Scaler =None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############Use Scaler =None\n",
    "# Ashley Hunt - psyah10\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "## Simple function to read a csv file and return a dataframe - If scaler is provided, it will scale the data\n",
    "def get_df(path, scaler=None, trim=True):\n",
    "      if not path.endswith('.csv'):\n",
    "            return []\n",
    "      \n",
    "      raw_data = pd.read_csv(path)\n",
    "      raw_data.columns = get_columns()\n",
    "\n",
    "      df = pd.DataFrame(scaler.fit_transform(raw_data) if scaler else raw_data, columns=raw_data.columns)\n",
    "\n",
    "      return trim_recording(df) if trim else df\n",
    "\n",
    "## Function to trim the recording to the first and last significant movement\n",
    "def trim_recording(df, padding=90):\n",
    "      window_size = 20\n",
    "      threshold = 0.3\n",
    "\n",
    "      df['rolling_max'] = df['accel_abs'].rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "      start_cut = df[df['rolling_max'] >= threshold].index.min()\n",
    "      if pd.notna(start_cut):\n",
    "            cut_index = max(start_cut - padding, 0)\n",
    "            df = df.loc[cut_index:]\n",
    "      \n",
    "      end_cut = df[df['rolling_max'] >= threshold].index.max()\n",
    "      if pd.notna(end_cut):\n",
    "            end_cut_index = min(end_cut + padding, len(df) - 1) \n",
    "            df = df.loc[:end_cut_index]\n",
    "\n",
    "      df = df.drop('rolling_max', axis=1)\n",
    "      return df\n",
    "\n",
    "## Function to get all the data from the files in the data folder\n",
    "def get_data_from_files(scaler=None):\n",
    "      dfs = []\n",
    "      for gesture in get_gestures():\n",
    "            for file_index, file_name in enumerate(get_gesture_csvs(gesture)):\n",
    "                  df = get_df(f'data/{gesture}/{file_name}', scaler)\n",
    "                  if len(df) == 0:\n",
    "                        continue\n",
    "\n",
    "                  df['file_number'] = int(file_index)\n",
    "                  df['file_name'] = str(file_name)\n",
    "                  df['gesture'] = str(gesture)\n",
    "\n",
    "                  dfs.append(df)\n",
    "\n",
    "      return pd.concat(dfs, ignore_index=True) if len(dfs) > 1 else dfs[0]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "df = get_data_from_files(None)\n",
    "#df.head()\n",
    "test_data = get_df(f'/Users/amitkumar/Downloads/Acceleration without g 2024-04-24 18-21-44 wave/Raw Data.csv', None)\n",
    "test_data['file_number'] = 0\n",
    "test_data['file_name'] = str(\"Raw Data\")\n",
    "test_data['gesture'] = str(\"go\")\n",
    "test_data\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "X = df.drop(columns=['gesture', 'time','file_name','file_number'])  # Features\n",
    "y = df['gesture']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'svm__C': [0.1],\n",
    "    'svm__kernel': ['rbf'],\n",
    "    'svm__gamma': ['scale']\n",
    "}\n",
    "\n",
    "\n",
    "#param_grid = {\n",
    "    #'svm__C': [0.1, 1, 10],\n",
    "    #'svm__kernel': ['linear', 'rbf'],\n",
    "    #'svm__gamma': ['scale', 'auto']\n",
    "#}\n",
    "\n",
    "# Create a pipeline with scaling and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', svm)\n",
    "])\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# Encode the target variable for test set\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search_svm = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search_svm.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get the best parameters and the best estimator from grid search\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_estimator_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best estimator\n",
    "y_pred_svm = best_estimator_svm.predict(X_test)\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_accuracy_svm = balanced_accuracy_score(y_test_encoded, y_pred_svm)\n",
    "\n",
    "# Display best parameters and balanced accuracy for SVM\n",
    "print(\"Best Parameters (SVM):\", best_params_svm)\n",
    "print(\"Balanced Accuracy (SVM):\", balanced_accuracy_svm)\n",
    "\n",
    "#Best Parameters (SVM): {'svm__C': 0.1, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
    "#Balanced Accuracy (SVM): 0.5483988039391403\n",
    "#TIME 5MIN\n",
    "#Keep for SVM\n",
    "#Lower accuracy 37.10 at\n",
    "#param_grid = {\n",
    "    #'svm__C': [0.1],\n",
    "    #'svm__kernel': ['linear'],\n",
    "    #'svm__gamma': ['scale']\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "\n",
    "\n",
    "X = df.drop(columns=['gesture', 'time','file_name','file_number'])  # Features\n",
    "y = df['gesture']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "#for train_index, test_index in sss.split(X, y):\n",
    "    #X_train, X_test = X[train_index], X[test_index]\n",
    "    #y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [250], #'n_estimators': [50, 100, 150]\n",
    "    'max_depth': [None], #'max_depth': [None, 10, 20]\n",
    "    'min_samples_split': [10], #'min_samples_split': [2, 5, 10]\n",
    "    'min_samples_leaf': [2] #'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    " \n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=3,scoring='balanced_accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    " \n",
    "y_pred = best_estimator.predict(X_test_scaled)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "\n",
    "\n",
    "# Combine the predicted and actual gestures with their corresponding time points\n",
    "results = pd.DataFrame({'Time (s)': X_test.index, 'Actual Gesture': y_test, 'Predicted Gesture': y_pred})\n",
    "\n",
    "# Print the results\n",
    "print(results)\n",
    "\n",
    "#59.333% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing\n",
    "#test_data---new data\n",
    "\n",
    "# Preprocess the new test data\n",
    "test_data_features = test_data.drop(columns=['gesture', 'time','file_name','file_number'])  # Features\n",
    "test_data_features_scaled = scaler.transform(test_data_features)  # Scale the features using the same scaler as before\n",
    "\n",
    "# Predict on the new test data\n",
    "y_pred_new = best_estimator.predict(test_data_features_scaled)\n",
    "\n",
    "# Calculate accuracy on the new test data\n",
    "accuracy_new = accuracy_score(test_data['gesture'], y_pred_new)\n",
    "\n",
    "# Combine the predicted and actual gestures with their corresponding time points\n",
    "results_new = pd.DataFrame({'Time (s)': test_data.index, 'Actual Gesture': test_data['gesture'], 'Predicted Gesture': y_pred_new})\n",
    "\n",
    "# Print the results along with accuracy\n",
    "print(results_new)\n",
    "print(\"Accuracy on new test data:\", accuracy_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB \n",
    "# Amit Kumar\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.drop(columns=['gesture', 'time','file_name','file_number'])  # Features\n",
    "y = df['gesture']  # Target variable\n",
    "\n",
    "#X = df.drop(columns=['gesture', 'time','file_name','gesture_number','file_number'])  # Features\n",
    "#y = df['gesture'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "#for train_index, test_index in sss.split(X, y):\n",
    "    #X_train, X_test = X[train_index], X[test_index]\n",
    "    #y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [20],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [1]\n",
    "}\n",
    "\n",
    "#param_grid = {\n",
    "    #'n_estimators': [50, 100, 150],\n",
    "    #'max_depth': [3, 5, 7],\n",
    "    #'learning_rate': [0.1, 0.01, 0.001],\n",
    "    #'subsample': [0.8, 0.9, 1.0],\n",
    "    #'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "#}\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# Encode the target variable for test set\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "balanced_accuracy = balanced_accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "\n",
    "#Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150, 'subsample': 0.8}\n",
    "#Balanced Accuracy: 0.6657678741988493\n",
    "\n",
    "#Best Parameters: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 300, 'subsample': 0.8}\n",
    "#Balanced Accuracy: 0.6817467817973307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = df\n",
    "\n",
    "# Encode the gesture labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['gesture_encoded'] = label_encoder.fit_transform(data['gesture'])\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "data[['accel_x', 'accel_y', 'accel_z', 'accel_abs']] = scaler.fit_transform(data[['accel_x', 'accel_y', 'accel_z', 'accel_abs']])\n",
    "\n",
    "# Define the time steps\n",
    "time_steps = 10\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "def prepare_data_for_lstm(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data.iloc[i:(i + time_steps)].values)\n",
    "        y.append(data.iloc[i + time_steps]['gesture_encoded'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = prepare_data_for_lstm(data[['accel_x', 'accel_y', 'accel_z', 'accel_abs', 'gesture_encoded']], time_steps)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax')) # Change activation to softmax for multi-class classification\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Change loss function for multi-class classification\n",
    "\n",
    "# Train the model with validation data\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
